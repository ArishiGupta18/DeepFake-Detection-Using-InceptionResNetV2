{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('deepfake-detection-model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 440ms/step\n",
      "Predicted class: [0]\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "Predicted class: [0]\n",
      "1/1 [==============================] - 0s 444ms/step\n",
      "Predicted class: [0]\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "Predicted class: [0]\n",
      "1/1 [==============================] - 1s 791ms/step\n",
      "Predicted class: [0]\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "Predicted class: [0]\n",
      "1/1 [==============================] - 1s 579ms/step\n",
      "Predicted class: [0]\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "Predicted class: [0]\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "Predicted class: [0]\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "Predicted class: [0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "cap = cv2.VideoCapture('test_videos/diopzaywor.mp4')\n",
    "\n",
    "frameRate = cap.get(5)\n",
    "while cap.isOpened():\n",
    "    frameId = cap.get(1)\n",
    "    ret, frame = cap.read()\n",
    "    if ret != True:\n",
    "        break\n",
    "    if frameId % ((int(frameRate)+1)*1) == 0:\n",
    "        face_rects, scores, idx = detector.run(frame, 0)\n",
    "        for i, d in enumerate(face_rects):\n",
    "            x1 = d.left()\n",
    "            y1 = d.top()\n",
    "            x2 = d.right()\n",
    "            y2 = d.bottom()\n",
    "            crop_img = frame[y1:y2, x1:x2]\n",
    "            data = img_to_array(cv2.resize(crop_img, (128, 128))).flatten() / 255.0\n",
    "            data = data.reshape(-1, 128, 128, 3)\n",
    "        \n",
    "            # Check if model predictions are working\n",
    "            predictions = model.predict(data)\n",
    "\n",
    "            # Check if class indexing is working\n",
    "            predicted_class = np.argmax(predictions, axis=1)\n",
    "            print(f'Predicted class: {predicted_class}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 35s 419ms/step - loss: 0.1245 - accuracy: 0.9859\n",
      "Training Loss: 0.12453217804431915\n",
      "Training Accuracy: 0.9858832359313965\n",
      "25/25 [==============================] - 10s 414ms/step - loss: 0.3307 - accuracy: 0.9148\n",
      "Validation Loss: 0.33067768812179565\n",
      "Validation Accuracy: 0.9147582650184631\n",
      "11/11 [==============================] - 5s 409ms/step - loss: 0.2293 - accuracy: 0.9024\n",
      "Test Loss: 0.2292659729719162\n",
      "Test Accuracy: 0.9023668766021729\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from deepfake_detection_train import X, Y\n",
    "\n",
    "\n",
    "# Assuming you have trained your model and it is stored in the variable 'model'\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=5)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.3, random_state=5)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "\n",
    "train_results = model.evaluate(X_train, Y_train)\n",
    "print(\"Training Loss:\", train_results[0])\n",
    "print(\"Training Accuracy:\", train_results[1])\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_results = model.evaluate(X_val, Y_val)\n",
    "print(\"Validation Loss:\", val_results[0])\n",
    "print(\"Validation Accuracy:\", val_results[1])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_results = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss:\", test_results[0])\n",
    "print(\"Test Accuracy:\", test_results[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
